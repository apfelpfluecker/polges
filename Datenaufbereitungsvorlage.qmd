# Datenaufbereitung

Achtung: In dem Ordner, in dem diese Datei liegt, muss auch eine "\_common.R" liegen, damit das Ganze funktioniert.

Diese Vorlage ist separat und nicht Teil der Arbeit. Hier kommt die gesamte Datenaufbereitung rein. Resultat sollte ein Datensatz sein, mit dem dann die Datenanalyse erfolgt. Das hat den Vorteil, dass Aufbereitung und Analyse getrennt werden und unabhängig voneinander erfolgen kann. Das minimiert auch die Fehleranfälligkeit.

```{r}
#| include: false
#| echo: false
#| warning: false
#| label: setup

source('_common.R')
library(tidyr)
library(sjPlot)
library(sjlabelled)
library(sjmisc)
library(stringr)

```

## Analyseebene 1: Individualdaten

```{r}
# Roh-Datensatz einlesen
sui_raw <- read_spss("data/sprache_und_identitaet_raw.sav")

# neuen Datesatz erstellen und nicht benötigte Informationen löschen
sui <- sui_raw %>% 
  select(
    S1,
    S2,
    S3,
    S4,
    S5_1,
    S5_2,
    S6,
    S7,
    S8o,
    S9o,
    S10,
    S11,
    S12,
    S13,
    Q1,
    Q2,
    Q13,
    Split_Q14,
  ) %>% 
  rename(
    age = S1,
    sex = S2,
    fed_state = S3,
    education = S4,
    polint = Q1,
    polinf = Q2,
    motong_ger = S5_1, # mother tongue
    motong_oth = S5_2,
    gainemp = S6, # gainful employment
    class = S7,
    housesize = S8o, # household size
    childinhouse = S9o, # children in household
    houseinc = S10, # household income
    commsize = S11, # community size
    party = S12,
    migback = S13, # migration background
    genatt = Q13 # attitude towards gender-neutral language
  ) %>% 
  mutate(eastwest = rec(
    fed_state,
    rec = "1,2,3,4,5,6,7,8,9,10 = 0 [West]; 12,13,14,15,16 = 1 [Ost]",
    var.label = "Ost-West-Zueghörigkeit",
    to.factor = TRUE
  )) %>% 
  mutate(educ = rec(
    education,
    rec = "1,2,3,5,6,7,8 = 0 [kein Studium]; 5 = 1 [Studium]",
    var.label = "Bildung (Studium)",
    to.factor = TRUE
  )) %>% 
  set_na(sex, na = 3) # Da sonst schwierig mit zu rechnen

sui <- set_na(sui, na = c(-66, 99, -99)) # unklar, was -66 bedeutet

saveRDS(sui, file = "data/sui.Rds")

```

## Analyseebene 2: Bundestagsanträge

```{r}
# Roh-Datensatz einlesen
bta_raw <- readRDS("data/btantraege_raw.Rds")

# alte Wahlperiode rauslöschen
bta_raw <- bta_raw %>% 
  filter(wahlperiode != 18)

# neuen Datensatz erstellen und nicht benötigte Informationen löschen
bta <- bta_raw %>% 
  # Bundesratsanträge rausfiltern
  filter(herausgeber == "BT") %>% 
  select(
    id,
    dokumentnummer,
    datum,
    wahlperiode,
    urheber,
    autoren_anzahl,
    titel,
    text) %>% 
  rename(
    doknr = dokumentnummer)

# Parteienvariablen erstellen und belegen
bta$spd <- str_detect(bta$urheber, "SPD")
bta$union <- str_detect(bta$urheber, "CDU/CSU")
bta$gruene <- str_detect(bta$urheber, "B90/GR")
bta$fdp <- str_detect(bta$urheber, "FDP")
bta$afd <- str_detect(bta$urheber, "AfD")
bta$linke <- str_detect(bta$urheber, regex("linke", ignore_case = TRUE)) # Groß-/Kleinschreibung egal
bta$bsw <- str_detect(bta$urheber, "BSW")
bta$bundesregierung <- str_detect(bta$urheber, "Bundesregierung")
bta$bundesministerien <- str_detect(bta$urheber, "Bundesministerium")

# Datensatz schön formatieren
bta <- bta %>% 
  # Liste Urheber in eigene Variablen
  #unnest_wider(urheber, names_sep = "_") %>% 
  # unnötige Variablen entfernen
  #select(
  #  -urheber_einbringer,
  #  -urheber_titel
  #) %>% 
  #rename(urheber = urheber_bezeichnung) %>% 
  # Variablenlabels hinzufügen
  var_labels(
    id = "ID",
    doknr = "Dokumentennummer",
    datum = "Antragsdatum",
    wahlperiode = "Wahlperiode",
    urheber = "Antragsteller",
    autoren_anzahl = "Autorenanzahl",
    titel = "Antragstitel",
    text = "Antragstext",
    spd = "SPD-Antrag",
    union = "Unions-Antrag",
    gruene = "Grünen-Antrag",
    fdp = "FDP-Antrag",
    afd = "AfD-Antrag",
    linke = "LINKE-Antrag",
    bsw = "BSW-Antrag",
    bundesregierung = "Antrag der Bundesregierung",
    bundesministerien = "Antrag eines Bundesministeriums"
  ) %>% 
  to_numeric(id)

# Filtervariable erstellen
# Übersicht über Platzhalter-Syntax: https://rstudio.github.io/cheatsheets/html/strings.html bzw. hier: https://stringr.tidyverse.org/articles/regular-expressions.html oder hier: https://mhesselbarth.github.io/advanced-r-workshop/cheatsheets/stringr.pdf
# 1. Filter filtert alles, was „Sprache“ enthält
bta_filter1 <- c("sprache+", "sprachlich+")
bta$filter1 <- str_detect(bta$text, regex(paste(bta_filter1, collapse = "|"), ignore_case = TRUE)) # Paste verbindet die beiden Strings durch die Bedingung collapse mit Und # ignore_case sorgt dafür, dass Groß-/Kleinschreibung egal ist

# 2. Filte filtert nach dem Thema
bta_filter2 <- c("gender+", "geschlecht(.*)gerecht+", "generisch+")
# neue Variable anlegen, die mit TRUE/FALSE bei Treffer/Nichttreffer belegt wird
bta$filter2 <- str_detect(bta$text, regex(paste(bta_filter2, collapse = "|"), ignore_case = TRUE)) # Paste verbindet die beiden Strings durch die Bedingung collapse mit Und # ignore_case sorgt dafür, dass Groß-/Kleinschreibung egal ist

# Kombination beider Filter-Variablen
bta$filter <- ifelse(bta$filter1 == TRUE & bta$filter2 == TRUE, TRUE, FALSE)

# Prüfen, ob ID einzigartig
anyDuplicated(bta$id) == 0 # wenn TRUE, dann einzigartig

# Manuelle Korrektur
#bta_ges <- select(bta_ges, -urheber)
#write.table(bta_ges, file="bta_ges.txt", dec = ",", sep = "\t")




#manuelle Korrektur
#bta_sub <- select(bta, id, filter, titel, text)

# [x] Kriterium: Sprache wird verwendet in Kombination mit Gender oder Geschlecht
# alternativ: Antrag zu dem Thema...
# Wichtig: thematisieren, dass Verwendung von geS keine Kodierung hervorruft
korrekturen <- c(274476, 273997, 273665, 273415, 272589, 271735, 271017, 271008, 270408, 269855, 269758, 268322, 268300, 268085, 267184, 266226, 265560, 266454, 265134, 264631, 264465, 264266, 264257, 264146, 263599, 263285, 263070, 262726, 261824, 261803, 260843, 259703, 258987, 258349, 257242, 255852, 256043, 255159, 254265, 254257, 254219, 253536, 253521, 252965, 252608, 251871, 251870, 251858, 251804, 251830, 251140, 251059, 251053, 251039, 250674, 250662, 250614, 249635, 248684, 247841, 247806, 247819, 247493, 246643, 246635, 246526, 245930, 245647, 245080, 245076, 245071, 244769, 244768, 244442, 242994, 242918, 242335, 242244, 242220, 241587, 241007, 241003, 240760, 240760, 238585, 237866, 237859, 237051, 235708, 235694, 235691, 235245, 234897, 234831, 233894, 231397, 229770, 229748, 229251, 227816, 227808, 227281, 227084, 226636, 226633, 226340, 226168, 224830, 224791, 224054, 223675, 223668, 223083, 222685, 222500, 220694, 220450, 220380)

for (i in korrekturen) {
  bta$filter[bta$id == i] <- FALSE
}

party <- c("SPD", "Union", "Grüne", "FDP", "AfD", "Linke", "BSW")
antraege_ges <- c(sum(bta$spd), sum(bta$union), sum(bta$gruene), sum(bta$fdp), sum(bta$afd), sum(bta$linke), sum(bta$bsw))
antraege_gen <- c(sum(bta$spd & bta$filter), sum(bta$union & bta$filter), sum(bta$gruene & bta$filter), sum(bta$fdp & bta$filter), sum(bta$afd & bta$filter), sum(bta$linke & bta$filter), sum(bta$bsw & bta$filter))
bta_new <- data.frame(party,antraege_ges, antraege_gen)

# Balkendiagramm für Anzahl der Anträge nach Parteien
ggplot(data = bta_new, aes(x = party, y = antraege_ges, fill = party)) +
  geom_bar(stat = "identity") +
  labs(title = "Anzahl der Anträge nach Parteien", x = "Partei", y = "Anzahl der Anträge")

# Balkendiagramm für Anzahl der Anträge für geschlechtergerechte Sprache
ggplot(data = bta_new, aes(x = party, y = antraege_gen, fill = party)) +
  geom_bar(stat = "identity") +
  labs(title = "Anzahl der Anträge für geschlechtergerechte Sprache", x = "Partei", y = "Anzahl der Anträge")


# Schlanken Datensatz erstellen
bta_sub <- bta %>% 
  select(id, wahlperiode, datum, spd, union, gruene, fdp, afd, linke, bsw, filter1, filter2, filter)





# funktioniert so nicht
bta <- bta %>% 
  group_by(filter == TRUE) %>% 
  mutate(party = case_when(spd == TRUE ~ 1,
                           union == TRUE ~ 2,
                           gruene == TRUE ~ 3,
                           fdp == TRUE ~ 4,
                           afd == TRUE ~ 5,
                           linke == TRUE ~ 6,
                           bsw == TRUE ~ 7)) %>% 
  rec(party, rec = "1 = 1 [SPD]; 2 = 2 [Union]; 3 = 3 [Grüne]; 4 = 4 [FDP]; 5 = 5 [AfD]; 6 = 6 [Linke]; 7 = 7 [BSW]", var.label = "Partei", to.factor = TRUE)

barplot(table(bta$filter, bta$), horiz = TRUE, beside = TRUE)

bta_sub <- bta %>% 
  select(id, filter2)
ids <- subset(bta_sub, filter2 == TRUE)$id
ids <- bta_sub$id[bta_sub$filter2 == TRUE]

# fertigen Datensatz speichern
saveRDS(bta, file = "data/btantraege.Rds")

```

```{r}
# neuen Datensatz erstellen für Parteiübersicht
# bei logischen Variablen werden bei sum() automatisch die TRUE-Werte gezählt
# Gesamtzahl der Anträge (absolut)
antr_gesamt <- c(
  sum(bta$spd), 
  sum(bta$union), 
  sum(bta$gruene), 
  sum(bta$fdp), 
  sum(bta$afd), 
  sum(bta$linke), 
  sum(bta$bsw),
  sum(bta$bundesregierung), 
  sum(bta$bundesministerien))

# Gesamtzahl der Anträge zum Thema Gendern (absolut)
antr_gendern <- c(
  sum(bta$spd & bta$filter), 
  sum(bta$union & bta$filter), 
  sum(bta$gruene & bta$filter), 
  sum(bta$fdp & bta$filter), 
  sum(bta$afd & bta$filter), 
  sum(bta$linke & bta$filter), 
  sum(bta$bsw & bta$filter),
  sum(bta$bundesregierung & bta$filter), 
  sum(bta$bundesministerien & bta$filter))

# Gesamtzahl der Anträge (relativ)
antr_gesamt_proz <- c(
  sum(bta$spd) / nrow(bta), 
  sum(bta$union) / nrow(bta), 
  sum(bta$gruene) / nrow(bta), 
  sum(bta$fdp) / nrow(bta), 
  sum(bta$afd) / nrow(bta), 
  sum(bta$linke) / nrow(bta), 
  sum(bta$bsw) / nrow(bta),
  sum(bta$bundesregierung) / nrow(bta),
  sum(bta$bundesministerien) / nrow(bta))*100

# Gesamtzahl der Anträge zum Thema Gendern (relativ)
antr_gendern_proz <- c(
  sum(bta$spd & bta$filter) / sum(bta$filter), 
  sum(bta$union & bta$filter) / sum(bta$filter), 
  sum(bta$gruene & bta$filter) / sum(bta$filter), 
  sum(bta$fdp & bta$filter) / sum(bta$filter), 
  sum(bta$afd & bta$filter) / sum(bta$filter), 
  sum(bta$linke & bta$filter) / sum(bta$filter), 
  sum(bta$bsw & bta$filter) / sum(bta$filter),
  sum(bta$bundesregierung & bta$filter) / sum(bta$filter), 
  sum(bta$bundesministerien & bta$filter) / sum(bta$filter))*100

# Verhältnis der Gender-thematisierenden Anträge zu den eigenen Anträgen
antr_gendern_gesamt <- c(
  sum(bta$spd & bta$filter) / sum(bta$spd), 
  sum(bta$union & bta$filter) / sum(bta$union), 
  sum(bta$gruene & bta$filter) / sum(bta$gruene), 
  sum(bta$fdp & bta$filter) / sum(bta$fdp), 
  sum(bta$afd & bta$filter) / sum(bta$afd), 
  sum(bta$linke & bta$filter) / sum(bta$linke), 
  sum(bta$bsw & bta$filter) / sum(bta$bsw),
  sum(bta$bundesregierung & bta$filter) / sum(bta$bundesregierung), 
  sum(bta$bundesministerien & bta$filter) / sum(bta$bundesministerien))*100

bta_sum <- data.frame(antr_gesamt, antr_gendern, antr_gesamt_proz, antr_gendern_proz, antr_gendern_gesamt)

rownames(bta_sum) <- c("SPD", "Union", "Grüne", "FDP", "AfD", "DIE LINKE", "BSW", "Bundesregierung", "Bundesministerien")

bta_sum <- bta_sum %>% 
  var_labels(
    antr_gesamt = "Gesamtzahl der Anträge",
    antr_gendern = "Gesamtzahl der geS-Anträge",
    antr_gesamt_proz = "Gesamtzahl der Anträge (relativ)",
    antr_gendern_proz = "Gesamtzahl der geS-Anträge (relativ)",
    antr_gendern_gesamt = "Verhältnis von geS-Anträgen zu eigenen Anträgen"
  )

# fertigen Datensatz speichern
saveRDS(bta_sum, file = "data/btantraege_sum.Rds")

```

## Analyseebene 3: Social-Media-Posts

...

```{r}
######################### Rohdatensatz SPD #########################
spd_raw <- read.csv2("data/social-media-data/spd.csv")
spd <- spd_raw %>% 
  filter(object_type == "data") %>% # alle Facepager-Statusmeldungen rausfiltern
  filter(message != "") %>%  # alle ausschließlichen Bild- und Video-Posts rausfiltern
  select(id, object_id, message, created_time) # unnötige Variablen entfernen

# generelle Filtervariable (thematisch)
sm_filter <- c("gender+", "geschlecht(.*)gerecht+", "generisch+")

# Filtern
spd$filter <- str_detect(spd$message, regex(paste(sm_filter, collapse = "|"), ignore_case = TRUE)) # Paste verbindet die beiden Strings durch die Bedingung collapse mit Und # ignore_case sorgt dafür, dass Groß-/Kleinschreibung egal ist
spd$party <- c(rep("SPD", nrow(spd)))
spd <- spd %>%  
  select(id, object_id, created_time, party, filter, message) # Reihenfolge der Variablen ändern

# Subset für die manuelle Filterkorrektur
write_csv2(subset(spd, filter == TRUE), "data/social-media-data/spd_korr.csv")

# Filterkorrektur
korrekturen <- c(89, 356, 447, 486, 546, 551, 559, 613, 622, 757, 893, 966, 1185, 1396, 1482, 2484, 2487, 2589, 2764)

for (i in korrekturen) {
  spd$filter[spd$id == i] <- FALSE
}


######################### Rohdatensatz CDU #########################
cdu_raw <- read.csv2("data/social-media-data/cdu.csv")
cdu <- cdu_raw %>% 
  filter(object_type == "data") %>% # alle Facepager-Statusmeldungen rausfiltern
  filter(message != "") %>%  # alle ausschließlichen Bild- und Video-Posts rausfiltern
  select(id, object_id, message, created_time) # unnötige Variablen entfernen

# Filtern
cdu$filter <- str_detect(cdu$message, regex(paste(sm_filter, collapse = "|"), ignore_case = TRUE)) # Paste verbindet die beiden Strings durch die Bedingung collapse mit Und # ignore_case sorgt dafür, dass Groß-/Kleinschreibung egal ist
cdu$party <- c(rep("CDU", nrow(cdu)))
cdu <- cdu %>%  
  select(id, object_id, created_time, party, filter, message) # Reihenfolge der Variablen ändern

# Subset für die manuelle Filterkorrektur
write_csv2(subset(cdu, filter == TRUE), "data/social-media-data/cdu_korr.csv")

# Filterkorrektur
korrekturen <- c(472, 484, 513, 695, 861, 909, 923, 956, 1022, 2106, 2453, 2754, 2800, 2960, 3045, 3583)

for (i in korrekturen) {
  cdu$filter[cdu$id == i] <- FALSE
}


######################### Rohdatensatz CSU #########################
csu_raw <- read.csv2("data/social-media-data/csu.csv")
csu <- csu_raw %>% 
  filter(object_type == "data") %>% # alle Facepager-Statusmeldungen rausfiltern
  filter(message != "") %>%  # alle ausschließlichen Bild- und Video-Posts rausfiltern
  select(id, object_id, message, created_time) # unnötige Variablen entfernen

# Filtern
csu$filter <- str_detect(csu$message, regex(paste(sm_filter, collapse = "|"), ignore_case = TRUE)) # Paste verbindet die beiden Strings durch die Bedingung collapse mit Und # ignore_case sorgt dafür, dass Groß-/Kleinschreibung egal ist
csu$party <- c(rep("CSU", nrow(csu)))
csu <- csu %>%  
  select(id, object_id, created_time, party, filter, message) # Reihenfolge der Variablen ändern

# Subset für die manuelle Filterkorrektur
write_csv2(subset(csu, filter == TRUE), "data/social-media-data/csu_korr.csv")

# Filterkorrektur
korrekturen <- c(983, 1160, 1287, 1567, 1874, 2240, 3284, 5284)

for (i in korrekturen) {
  csu$filter[csu$id == i] <- FALSE
}


######################### Rohdatensatz Grüne #########################
gruene_raw <- read.csv2("data/social-media-data/gruene.csv")
gruene <- gruene_raw %>% 
  filter(object_type == "data") %>% # alle Facepager-Statusmeldungen rausfiltern
  filter(message != "") %>%  # alle ausschließlichen Bild- und Video-Posts rausfiltern
  select(id, object_id, message, created_time) # unnötige Variablen entfernen

# Filtern
gruene$filter <- str_detect(gruene$message, regex(paste(sm_filter, collapse = "|"), ignore_case = TRUE)) # Paste verbindet die beiden Strings durch die Bedingung collapse mit Und # ignore_case sorgt dafür, dass Groß-/Kleinschreibung egal ist
gruene$party <- c(rep("Bündnis 90/Die Grünen", nrow(gruene)))
gruene <- gruene %>%  
  select(id, object_id, created_time, party, filter, message) # Reihenfolge der Variablen ändern

# Subset für die manuelle Filterkorrektur
write_csv2(subset(gruene, filter == TRUE), "data/social-media-data/gruene_korr.csv")

# Filterkorrektur
korrekturen <- c(6, 52, 77, 119, 260, 594, 659, 700, 780, 812, 815, 880, 895, 957, 958, 1158, 1348, 1375, 1465, 1697)

for (i in korrekturen) {
  gruene$filter[gruene$id == i] <- FALSE
}


######################### Rohdatensatz FDP #########################
fdp_raw <- read.csv2("data/social-media-data/fdp.csv")
fdp <- fdp_raw %>% 
  filter(object_type == "data") %>% # alle Facepager-Statusmeldungen rausfiltern
  filter(message != "") %>%  # alle ausschließlichen Bild- und Video-Posts rausfiltern
  select(id, object_id, message, created_time) # unnötige Variablen entfernen

# Filtern
fdp$filter <- str_detect(fdp$message, regex(paste(sm_filter, collapse = "|"), ignore_case = TRUE)) # Paste verbindet die beiden Strings durch die Bedingung collapse mit Und # ignore_case sorgt dafür, dass Groß-/Kleinschreibung egal ist
fdp$party <- c(rep("FDP", nrow(fdp)))
fdp <- fdp %>%  
  select(id, object_id, created_time, party, filter, message) # Reihenfolge der Variablen ändern

# Subset für die manuelle Filterkorrektur
write_csv2(subset(fdp, filter == TRUE), "data/social-media-data/fdp_korr.csv")

# Filterkorrektur
korrekturen <- c(475, 476, 535, 542, 544, 578, 745, 912, 1103, 1105, 1121, 1233, 1311, 1318, 1795, 2064, 2091, 2325, 2777, 2789, 3033, 3198, 3596, 3713, 3779, 3927)

for (i in korrekturen) {
  fdp$filter[fdp$id == i] <- FALSE
}


######################### Rohdatensatz AfD #########################
afd_raw <- read.csv2("data/social-media-data/afd.csv")
afd <- afd_raw %>% 
  filter(object_type == "data") %>% # alle Facepager-Statusmeldungen rausfiltern
  filter(message != "") %>%  # alle ausschließlichen Bild- und Video-Posts rausfiltern
  select(id, object_id, message, created_time) # unnötige Variablen entfernen

# Filtern
afd$filter <- str_detect(afd$message, regex(paste(sm_filter, collapse = "|"), ignore_case = TRUE)) # Paste verbindet die beiden Strings durch die Bedingung collapse mit Und # ignore_case sorgt dafür, dass Groß-/Kleinschreibung egal ist
afd$party <- c(rep("AfD", nrow(afd)))
afd <- afd %>% 
  select(id, object_id, created_time, party, filter, message) # Reihenfolge der Variablen ändern

# Subset für die manuelle Filterkorrektur
write_csv2(subset(afd, filter == TRUE), "data/social-media-data/afd_korr.csv")

# Filterkorrektur
korrekturen <- c(5, 50, 62, 142, 174, 189, 234, 396, 398, 412, 448, 513, 514, 643, 768, 776, 922, 928, 1053, 1192, 1201, 1233, 1235, 1242, 1249, 1275, 1297, 1300, 1303, 1309, 1322, 1334, 1344, 1364, 1394, 1398, 1407, 1409, 1413, 1433, 1435, 1453, 1454, 1481, 1486, 1496, 1537, 1589, 1652, 1689, 1742, 1761, 1781, 1878, 2145, 2157, 2214, 2216, 2217, 2254, 2276, 2398, 2399, 2418, 2429, 2441, 2454, 2464, 2652, 2661, 2725, 2757, 2799, 3005, 3202, 3271, 3360, 3453, 3465, 3661, 4053, 4301, 4556, 4590, 4705, 4734, 4766, 4782, 4898, 4900, 4963, 4975, 5049, 5233, 5249)

for (i in korrekturen) {
  afd$filter[afd$id == i] <- FALSE
}


######################### Rohdatensatz Linke #########################
linke_raw <- read.csv2("data/social-media-data/linke.csv")
linke <- linke_raw %>% 
  filter(object_type == "data") %>% # alle Facepager-Statusmeldungen rausfiltern
  filter(message != "") %>%  # alle ausschließlichen Bild- und Video-Posts rausfiltern
  select(id, object_id, message, created_time) # unnötige Variablen entfernen

# Filtern
linke$filter <- str_detect(linke$message, regex(paste(sm_filter, collapse = "|"), ignore_case = TRUE)) # Paste verbindet die beiden Strings durch die Bedingung collapse mit Und # ignore_case sorgt dafür, dass Groß-/Kleinschreibung egal ist
linke$party <- c(rep("Die Linke", nrow(linke)))
linke <- linke %>%  
  select(id, object_id, created_time, party, filter, message) # Reihenfolge der Variablen ändern

# Subset für die manuelle Filterkorrektur
write_csv2(subset(linke, filter == TRUE), "data/social-media-data/linke_korr.csv")

# Filterkorrektur
korrekturen <- c(220, 371, 388, 421, 492, 508, 750, 1181, 1922, 2105, 2255, 2264, 2354)

for (i in korrekturen) {
  linke$filter[linke$id == i] <- FALSE
}


######################### Rohdatensatz BSW #########################
bsw_raw <- read.csv2("data/social-media-data/bsw.csv")
bsw <- bsw_raw %>% 
  filter(object_type == "data") %>% # alle Facepager-Statusmeldungen rausfiltern
  filter(message != "") %>%  # alle ausschließlichen Bild- und Video-Posts rausfiltern
  select(id, object_id, message, created_time) # unnötige Variablen entfernen

# Filtern
bsw$filter <- str_detect(bsw$message, regex(paste(sm_filter, collapse = "|"), ignore_case = TRUE)) # Paste verbindet die beiden Strings durch die Bedingung collapse mit Und # ignore_case sorgt dafür, dass Groß-/Kleinschreibung egal ist
bsw$party <- c(rep("BSW", nrow(bsw)))
bsw <- bsw %>%  
  select(id, object_id, created_time, party, filter, message) # Reihenfolge der Variablen ändern

# Subset für die manuelle Filterkorrektur
write_csv2(subset(bsw, filter == TRUE), "data/social-media-data/bsw_korr.csv")

# Filterkorrektur
korrekturen <- c()

for (i in korrekturen) {
  bsw$filter[bsw$id == i] <- FALSE
}


######################### Zusammenfügen der Daten in einen Datensatz #########################
fb_posts <- rbind(spd, cdu, csu, gruene, fdp, afd, linke, bsw)
# Test, ob Zeilenlängen gleich sind
if(sum(nrow(spd),nrow(cdu),nrow(csu),nrow(gruene),nrow(fdp),nrow(afd),nrow(linke),nrow(bsw)) != nrow(fb_posts)) {
  "Achtung! Ungleiche Zeilenlänge von Ausgangsdaten und neuem Datensatz."
}

# created_time in richtiges Datumsformat umwandeln
fb_posts$created_time <- as.Date(fb_posts$created_time)

# Filtern: Erst ab 24.10.2017
fb_posts <- fb_posts %>% 
  filter(created_time >= as.Date("2017-10-24"))

# fertigen Datensatz abspeichern
saveRDS(fb_posts, file = "data/fb_posts.Rds")
# Datensatz zum Codieren abspeichern
write_csv2(filter(fb_posts, filter == TRUE), "data/social-media-data/fb_posts_cod.csv")

```

```{r}
# Marktanteile aller Social-Media-Plattformen in Deutschland
sm_17 <- read.csv("data/social-media-data/marktanteil/sm-2017.csv")
sm_17 <- sm_17 %>% 
  mutate(Other = rowSums(select(., c(StumbleUpon, VKontakte, Google., news.ycombinator.com, Fark, Other)), na.rm = TRUE)) %>% 
  select(Date, Facebook, Pinterest, Tumblr, Twitter, YouTube, Instagram, reddit, LinkedIn, Other)
sm_18 <- read.csv("data/social-media-data/marktanteil/sm-2018.csv")
sm_18 <- sm_18 %>% 
  mutate(Other = rowSums(select(., c(StumbleUpon, VKontakte, Google., news.ycombinator.com, Other)), na.rm = TRUE)) %>% 
  select(Date, Facebook, Pinterest, Tumblr, Twitter, YouTube, Instagram, reddit, LinkedIn, Other)
sm_19 <- read.csv("data/social-media-data/marktanteil/sm-2019.csv")
sm_19 <- sm_19 %>% 
  mutate(Other = rowSums(select(., c(StumbleUpon, VKontakte, Google., news.ycombinator.com, Other)), na.rm = TRUE)) %>% 
  select(Date, Facebook, Pinterest, Tumblr, Twitter, YouTube, Instagram, reddit, LinkedIn, Other)
sm_20 <- read.csv("data/social-media-data/marktanteil/sm-2020.csv")
sm_20 <- sm_20 %>% 
  mutate(Other = rowSums(select(., c(StumbleUpon, VKontakte, Google., news.ycombinator.com, Vimeo, Other)), na.rm = TRUE)) %>% 
  select(Date, Facebook, Pinterest, Tumblr, Twitter, YouTube, Instagram, reddit, LinkedIn, Other)
sm_21 <- read.csv("data/social-media-data/marktanteil/sm-2021.csv")
sm_21 <- sm_21 %>% 
  mutate(Other = rowSums(select(., c(StumbleUpon, VKontakte, Sina.Weibo, news.ycombinator.com, Vimeo, Other)), na.rm = TRUE)) %>% 
  select(Date, Facebook, Pinterest, Tumblr, Twitter, YouTube, Instagram, reddit, LinkedIn, Other)
sm_22 <- read.csv("data/social-media-data/marktanteil/sm-2022.csv")
sm_22 <- sm_22 %>% 
  mutate(Other = rowSums(select(., c(StumbleUpon, VKontakte, Sina.Weibo, news.ycombinator.com, Vimeo, Other)), na.rm = TRUE)) %>% 
  select(Date, Facebook, Pinterest, Tumblr, Twitter, YouTube, Instagram, reddit, LinkedIn, Other)
sm_23 <- read.csv("data/social-media-data/marktanteil/sm-2023.csv")
sm_23 <- sm_23 %>% 
  mutate(Other = rowSums(select(., c(StumbleUpon, VKontakte, news.ycombinator.com, Other)), na.rm = TRUE)) %>% 
  select(Date, Facebook, Pinterest, Tumblr, Twitter, YouTube, Instagram, reddit, LinkedIn, Other)
sm_last12 <- read.csv("data/social-media-data/marktanteil/sm-last12.csv")
sm_last12 <- sm_last12 %>% 
  mutate(Other = rowSums(select(., c(StumbleUpon, VKontakte, Sina.Weibo, news.ycombinator.com, Other)), na.rm = TRUE)) %>% 
  select(Date, Facebook, Pinterest, Tumblr, Twitter, YouTube, Instagram, reddit, LinkedIn, Other)
# Zusammenfügen
sm_marktanteile <- rbind(sm_17, sm_18, sm_19, sm_20, sm_21, sm_22, sm_23, sm_last12)
# Zeilen außerhalb des Untersuchungszeitraums löschen
sm_marktanteile <- sm_marktanteile[-(1:9), ]
saveRDS(sm_marktanteile, "data/sm_marktanteile.Rds")

```
